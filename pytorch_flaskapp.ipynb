{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_flaskapp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC_MySyxCo_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "2a9c2586-9123-496f-92c8-de591666e6a2"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAY80SZoCymC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "30f51d99-fd37-4c81-c0ac-b8b52ba2a9c4"
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"Hello World!! from Google Colab\"\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = get_model()\n",
        "soft = nn.Softmax(dim=1)\n",
        "\n",
        "# @app.route(\"/predict\")\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    req = request.values.to_dict()\n",
        "    sentence = req['text']\n",
        "    # sentence = \"언젠가 다시 보고 싶은 영화\"\n",
        "    print(req)\n",
        "\n",
        "\n",
        "    rating, posneg = model.inference(sentence)\n",
        "    rating_soft = soft(rating)\n",
        "    posneg_soft = soft(posneg)\n",
        "    \n",
        "    ret = dict()\n",
        "    ret['emotion_percent'] = round(100 - (torch.max(rating_soft).item() * 100), 2)\n",
        "    ret['movie_rating'] = torch.argmax(rating_soft).item()\n",
        "    ret['pos_or_neg'] = torch.argmax(posneg_soft).item() # 0:부정, 1:긍정\n",
        "    print(ret)\n",
        "    # res = jsonify(ret)\n",
        "    # res = flask.make_response(ret)\n",
        "\n",
        "    # print(res)\n",
        "    # res = flask.make_response(ret)\n",
        "    \n",
        "    # if ret['pos_or_neg'] == 0:\n",
        "    #     ps = '부정'\n",
        "    # else:\n",
        "    #     ps = '긍정'\n",
        "\n",
        "    # tmp = \"입력하신 문장 \\'\" + sentence + \"\\'의 예측 평점은 \" + str(ret['movie_rating']) + \" 이고 \" + str(ret['emotion_percent']) + \"%확률로 \" + ps + \" 문장입니다.\"\n",
        "    \n",
        "    return ret\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n",
            "load model\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://ac8484fe2df6.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:22:38] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'text': '우와 너무 재밌어요!우와 너무 재밌어요!우와 너무 재밌어요!우와 너무 재밌어요!우와 너무 재밌어요!우와 너무 재밌어요!우와 너무 재밌어요!'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:27:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 78.58, 'movie_rating': 10, 'pos_or_neg': 1}\n",
            "{'text': '와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:28:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 78.88, 'movie_rating': 3, 'pos_or_neg': 0}\n",
            "{'text': '우와 정말 최고다! 저의 인생영화입니다. 이런 영화 다시 볼 수 없을듯...'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:33:41] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 76.99, 'movie_rating': 8, 'pos_or_neg': 1}\n",
            "{'text': '진짜 최악... 다시는 이런 영화 보고 싶지 않습니다. 눈썩....'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:34:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 79.48, 'movie_rating': 3, 'pos_or_neg': 0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:41:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [05/Sep/2020 11:41:28] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'text': '와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:47:37] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 77.55, 'movie_rating': 3, 'pos_or_neg': 0}\n",
            "{'text': '와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..와 핵노잼..'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:48:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 77.66, 'movie_rating': 3, 'pos_or_neg': 0}\n",
            "{'text': '최악 진짜 이런 영화 다시 보기 싫다 진짜 이 영화는 와.....'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:48:31] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 80.68, 'movie_rating': 3, 'pos_or_neg': 0}\n",
            "{'text': '와 핵노잼..힘들구만 우짜노힘들구만 우짜노힘들구만 우짜노와 핵노잼..힘들구만 우짜노힘들구만 우짜노힘들구만 우짜노와 핵노잼..힘들구만 우짜노힘들구만 우짜노힘들구만 우짜노와 핵노잼..힘들구만 우짜노힘들구만 우짜노힘들구만 우짜노'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:48:38] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 79.73, 'movie_rating': 3, 'pos_or_neg': 0}\n",
            "{'text': '가슴이 웅장해집니다가슴이 웅장해집니다가슴이 웅장해집니다가슴이 웅장해집니다가슴이 웅장해집니다'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:48:43] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 70.6, 'movie_rating': 9, 'pos_or_neg': 1}\n",
            "{'text': '가슴이 두근두근 하네요 가슴이 두근두근 하네요  가슴이 두근두근 하네요 '}\n",
            "{'text': '가슴이 두근두근 하네요 가슴이 두근두근 하네요  가슴이 두근두근 하네요 '}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Sep/2020 11:48:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [05/Sep/2020 11:48:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'emotion_percent': 73.34, 'movie_rating': 9, 'pos_or_neg': 1}\n",
            "{'emotion_percent': 73.99, 'movie_rating': 9, 'pos_or_neg': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsxdyCQtEPpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5beceb5c-7fc9-4dd1-b5fc-c992c70e59ec"
      },
      "source": [
        "!pip install gluonnlp\n",
        "!pip install mxnet-cu101\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install transformers==2.1.1\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\r\u001b[K     |█                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp36-cp36m-linux_x86_64.whl size=588513 sha256=09aadefa2d14a64fa7a7c7e1f58c255c197d6401fbfc991ca869f528930e65c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/26/9655677b901537f367c3c473376e4106abc72e01a8fc25b1cb6ed9c37e8c/mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0MB)\n",
            "\u001b[K     |███████████████████████████████▌| 834.1MB 1.4MB/s eta 0:00:09tcmalloc: large alloc 1147494400 bytes == 0x65eb0000 @  0x7ff7ef545615 0x591f47 0x4cc229 0x4cc38b 0x50a51c 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50cfd6 0x58e793 0x50c467 0x58e793 0x50c467 0x58e793 0x50c467 0x58e793 0x50c467 0x509918 0x50a64d 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x509918 0x50a64d\n",
            "\u001b[K     |████████████████████████████████| 846.0MB 22kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.6.20)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.7.0\n",
            "Collecting sentencepiece==0.1.85\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting transformers==2.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.14.48)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (0.1.85)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2019.12.20)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (1.17.48)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (0.16.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->transformers==2.1.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->transformers==2.1.1) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1dd56cc4648ac09a317fd9fa261a95ef85cd8ac27faf73a232337f34c5a792b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 transformers-2.1.1\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-5b_yt6oj\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-5b_yt6oj\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.1-cp36-none-any.whl size=12820 sha256=4d571d1f88a22fd4930bb028529a2b8a6c99a320549bcc3af43af35d59a91cdb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g8cpcgi1/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMQBOG0EGY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import WarmupLinearSchedule\n",
        "\n",
        "##GPU 사용 시\n",
        "# device = torch.device(\"cuda:0\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=2,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        np_classifier = self.classifier(out)\n",
        "        return out, np_classifier\n",
        "\n",
        "class new_bert(nn.Module):\n",
        "    def __init__(self, model, hidden_size = 768):\n",
        "        super(new_bert, self).__init__()\n",
        "        self.main_model = model\n",
        "        self.fc1 = nn.Linear(hidden_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 11) # output is rating.\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        x, np_cls = self.main_model(token_ids, valid_length, segment_ids)\n",
        "        x = self.fc1(x)\n",
        "        \n",
        "        x = F.gelu(x)\n",
        "        rating_pred = self.fc2(x)\n",
        "        return rating_pred, np_cls\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, rating_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "        \n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.ratings = [np.int32(i[rating_idx]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "       \n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.ratings[i], ) + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 30\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5\n",
        "\n",
        "class get_model():\n",
        "    def __init__(self):\n",
        "        self.bertmodel, self.vocab = get_pytorch_kobert_model()\n",
        "        self.tokenizer = get_tokenizer()\n",
        "        self.tok = nlp.data.BERTSPTokenizer(self.tokenizer, self.vocab, lower=False)\n",
        "        self.old_model = BERTClassifier(self.bertmodel,  dr_rate=0.5).to(device)\n",
        "        self.to_model = new_bert(self.old_model).to(device)\n",
        "        load_model = True\n",
        "        start_point = 24\n",
        "        if load_model:\n",
        "            self.to_model.load_state_dict(torch.load('/content/drive/My Drive/model_'+str(start_point), map_location=device))\n",
        "            print(\"load model\")\n",
        "\n",
        "    def calc_accuracy(self, X, Y):\n",
        "        max_vals, max_indices = torch.max(X, 1)\n",
        "        train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "        return train_acc\n",
        "    \n",
        "    def inference(self, input_x):\n",
        "        transform = nlp.data.BERTSentenceTransform(self.tok, max_seq_length=max_len, pad=True, pair=False)\n",
        "        #input_set = nlp.data.TSVDataset(input_x, field_indices=[0])\n",
        "        \n",
        "        query = transform([input_x])\n",
        "        \n",
        "        query_2 = np.zeros_like([1])\n",
        "        query_2[0] = query[1]\n",
        "     \n",
        "        token_ids = torch.LongTensor(query[0]).unsqueeze(0).to(device)\n",
        "        length = torch.LongTensor(query_2)\n",
        "        segment_ids = torch.LongTensor(query[2]).unsqueeze(0).to(device)\n",
        "   \n",
        "        rating_pred, np_cls = self.to_model(token_ids, length, segment_ids)\n",
        "        return rating_pred, np_cls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TARM-ZciC2Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "72d67a34-e630-4948-8952-3bfa4725e05a"
      },
      "source": [
        "# import get_model as m\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# def main():\n",
        "test = get_model()\n",
        "    \n",
        "q_sentence = [\"만악의근원 아멜리아. 걸러야됨\",\n",
        "\"이 영화를 보기전의 나에게 나도 책꽃이를 두드리며 애걸복걸 하고 있었겠지. 안돼 !!! 보지마!!!\",\n",
        "\"실망치가 커서 평점을 낮게 줌 169분 런닝타임중에 69분은 정말 지루하고(느린 진행에 속터짐) 나머지 100분은 볼만한 정도,, 그리고 블랙홀에서;;; 평가 : 이영화에 비하면 그레비티는 개꿀잼 결론...\",\n",
        "\"있어보이려고 감동적이라고 말하는 사람들....이 영화는 말그대로 판타지다 결말은 단순하다 우리가 현재의 삶을 더 나은 방식으로 혹은 과거로 되돌리기위해 우주로 떠난다는 이야기의 내용이다 과거를 소재로 하는 내용에는 ...\",\n",
        "\"넷플릭스로 본 영화지만 2시간 49분이라는 시간 안에 스토리가 흐름이 아주 좋았습니다. 저거 만드느라 제작기간이 엄청 길었을텐데 용케도 해냈네요.\",\n",
        "\"꿀잼\"\n",
        "]\n",
        "answer = [1,1,2,5,10,10]\n",
        "    \n",
        "soft = nn.Softmax(dim=1)\n",
        "# 1~10 rating.\n",
        "# 부정 0 긍정 1\n",
        "for i, j in zip(q_sentence, answer):\n",
        "    rating, posneg = test.inference(i)\n",
        "    rating_soft = soft(rating)\n",
        "    posneg_soft = soft(posneg)\n",
        "    print(\"Input_sentence: \", i)\n",
        "    print(\"origin_answer: \",j)\n",
        "    print(\"예상되는 점수는: \", torch.argmax(rating_soft).item())\n",
        "    if posneg_soft.argmax().item() == 0:\n",
        "        print(\"%.2f%% 확률로 부정적인 문장입니다.\"%(100 - (torch.max(rating_soft).item() * 100)))\n",
        "    else:\n",
        "        print(\"%.2f%% 확률로 긍정적인 문장입니다.\"%(100 - (torch.max(rating_soft).item() * 100)))\n",
        "    print()\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n",
            "load model\n",
            "Input_sentence:  만악의근원 아멜리아. 걸러야됨\n",
            "origin_answer:  1\n",
            "예상되는 점수는:  3\n",
            "78.04% 확률로 부정적인 문장입니다.\n",
            "\n",
            "Input_sentence:  이 영화를 보기전의 나에게 나도 책꽃이를 두드리며 애걸복걸 하고 있었겠지. 안돼 !!! 보지마!!!\n",
            "origin_answer:  1\n",
            "예상되는 점수는:  3\n",
            "81.34% 확률로 부정적인 문장입니다.\n",
            "\n",
            "Input_sentence:  실망치가 커서 평점을 낮게 줌 169분 런닝타임중에 69분은 정말 지루하고(느린 진행에 속터짐) 나머지 100분은 볼만한 정도,, 그리고 블랙홀에서;;; 평가 : 이영화에 비하면 그레비티는 개꿀잼 결론...\n",
            "origin_answer:  2\n",
            "예상되는 점수는:  3\n",
            "82.70% 확률로 부정적인 문장입니다.\n",
            "\n",
            "Input_sentence:  있어보이려고 감동적이라고 말하는 사람들....이 영화는 말그대로 판타지다 결말은 단순하다 우리가 현재의 삶을 더 나은 방식으로 혹은 과거로 되돌리기위해 우주로 떠난다는 이야기의 내용이다 과거를 소재로 하는 내용에는 ...\n",
            "origin_answer:  5\n",
            "예상되는 점수는:  7\n",
            "83.91% 확률로 부정적인 문장입니다.\n",
            "\n",
            "Input_sentence:  넷플릭스로 본 영화지만 2시간 49분이라는 시간 안에 스토리가 흐름이 아주 좋았습니다. 저거 만드느라 제작기간이 엄청 길었을텐데 용케도 해냈네요.\n",
            "origin_answer:  10\n",
            "예상되는 점수는:  9\n",
            "68.15% 확률로 긍정적인 문장입니다.\n",
            "\n",
            "Input_sentence:  꿀잼\n",
            "origin_answer:  10\n",
            "예상되는 점수는:  10\n",
            "81.11% 확률로 긍정적인 문장입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-1Do97aOn7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0ab1c462-5c8a-4a56-f894-8ab3a96c7059"
      },
      "source": [
        "# import get_model as m\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# test = get_model()\n",
        "# soft = nn.Softmax(dim=1)\n",
        "\n",
        "sentence = \"언젠가 다시 보고 싶은 영화\"\n",
        "\n",
        "rating, posneg = test.inference(sentence)\n",
        "rating_soft = soft(rating)\n",
        "posneg_soft = soft(posneg)\n",
        "print(\"Input_sentence: \", sentence)\n",
        "print(\"예상되는 점수는: \", torch.argmax(rating_soft).item())\n",
        "if posneg_soft.argmax().item() == 0:\n",
        "    print(\"%.2f%% 확률로 부정적인 문장입니다.\"%(100 - (torch.max(rating_soft).item() * 100)))\n",
        "else:\n",
        "    print(\"%.2f%% 확률로 긍정적인 문장입니다.\"%(100 - (torch.max(rating_soft).item() * 100)))\n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input_sentence:  언젠가 다시 보고 싶은 영화\n",
            "예상되는 점수는:  10\n",
            "75.07% 확률로 긍정적인 문장입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXIP0EUyx82q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}